HDFS : 분산 파일 시스템
MapReduce : 분산 처리 시스템

일반적으로 위 두 가지는 물리적으로 같은 서버에 공존한다.
하나의 마스터 & 다중 슬레이브 구조 -> 각 서버마다 HDFS 슬레이브와 MapReduce 슬레이브가 같이 놓임

처리한 데이터를 MySql에 넣으려면 Sqoop 사용

### 병렬 처리를 위한 데이터 모델
- 데이터 = 레코드 집합
- 각 레코드는 key-value 쌍으로 구성

MapReduce는 입력 데이터를 HDFS에서 읽고 output 또한 HDFS로 보냄
HDFS에서 특정 dir를 데이터 노드가 블록을 저장할 장소로 정하기만 하면 됨

* 실시간 처리에는 적합하지 않음

- 하드웨어 고장에 유연한 대처
	데이터 블록을 일반적으로 3군데에 저장 -> 어떤 데이터노드에 문제 발생하더라도 문제 인식 시 바로 해당 데이터노드 정보를 다른 곳에 복제(언제나 복제본 숫자 유지)

## SQOOP
RDB와 Hadoop 사이 데이터 이동을 맡는 중간 어플리케이션

- import : RDB에서 HDFS에 데이터 보냄
- export : HDFS에서 RDB에 데이터 보냄

### 잘라서 가져오기
import 하는 sql 문에 $CONDITIONS 넣기 + 자를 열 기준 정하는 -split-by 필수

